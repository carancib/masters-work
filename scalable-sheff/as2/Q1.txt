Conda uses environments to load different sets of Python packages
type conda env list to see the environments availible.
2019-04-02 13:45:58 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-04-02 13:46:01 INFO  SparkContext:54 - Running Spark version 2.3.2
2019-04-02 13:46:01 WARN  SparkConf:66 - In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).
2019-04-02 13:46:01 INFO  SparkContext:54 - Submitted application: COM6012 Assignment 2
2019-04-02 13:46:01 INFO  SecurityManager:54 - Changing view acls to: acp18ca
2019-04-02 13:46:01 INFO  SecurityManager:54 - Changing modify acls to: acp18ca
2019-04-02 13:46:01 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-04-02 13:46:01 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-04-02 13:46:01 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(acp18ca); groups with view permissions: Set(); users  with modify permissions: Set(acp18ca); groups with modify permissions: Set()
2019-04-02 13:46:01 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 42861.
2019-04-02 13:46:01 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-04-02 13:46:01 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-04-02 13:46:01 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-04-02 13:46:01 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-04-02 13:46:01 INFO  DiskBlockManager:54 - Created local directory at /scratch/4030607.1.rse-com6012.q/blockmgr-d1e5d8dd-ffe5-441c-8350-1ddbe1c95e2d
2019-04-02 13:46:01 INFO  MemoryStore:54 - MemoryStore started with capacity 16.9 GB
2019-04-02 13:46:01 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-04-02 13:46:02 INFO  log:192 - Logging initialized @4658ms
2019-04-02 13:46:02 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-04-02 13:46:02 INFO  Server:419 - Started @4715ms
2019-04-02 13:46:02 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2019-04-02 13:46:02 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2019-04-02 13:46:02 INFO  AbstractConnector:278 - Started ServerConnector@71ed2af7{HTTP/1.1,[http/1.1]}{0.0.0.0:4042}
2019-04-02 13:46:02 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4042.
2019-04-02 13:46:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32c81163{/jobs,null,AVAILABLE,@Spark}
2019-04-02 13:46:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5df376fe{/jobs/json,null,AVAILABLE,@Spark}
2019-04-02 13:46:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@8b76501{/jobs/job,null,AVAILABLE,@Spark}
2019-04-02 13:46:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a433ded{/jobs/job/json,null,AVAILABLE,@Spark}
2019-04-02 13:46:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c41eedd{/stages,null,AVAILABLE,@Spark}
2019-04-02 13:46:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7fed0539{/stages/json,null,AVAILABLE,@Spark}
2019-04-02 13:46:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@467e0881{/stages/stage,null,AVAILABLE,@Spark}
2019-04-02 13:46:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1e6d9a7{/stages/stage/json,null,AVAILABLE,@Spark}
2019-04-02 13:46:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@376af31a{/stages/pool,null,AVAILABLE,@Spark}
2019-04-02 13:46:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6d3e3248{/stages/pool/json,null,AVAILABLE,@Spark}
2019-04-02 13:46:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55a7f490{/storage,null,AVAILABLE,@Spark}
2019-04-02 13:46:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@623b3462{/storage/json,null,AVAILABLE,@Spark}
2019-04-02 13:46:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2a9f91c{/storage/rdd,null,AVAILABLE,@Spark}
2019-04-02 13:46:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1e193773{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-04-02 13:46:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74705354{/environment,null,AVAILABLE,@Spark}
2019-04-02 13:46:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd3f19c{/environment/json,null,AVAILABLE,@Spark}
2019-04-02 13:46:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@27f9063{/executors,null,AVAILABLE,@Spark}
2019-04-02 13:46:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@558a9df0{/executors/json,null,AVAILABLE,@Spark}
2019-04-02 13:46:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@23168ee6{/executors/threadDump,null,AVAILABLE,@Spark}
2019-04-02 13:46:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7319c409{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-04-02 13:46:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d1bbe81{/static,null,AVAILABLE,@Spark}
2019-04-02 13:46:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@18b9e397{/,null,AVAILABLE,@Spark}
2019-04-02 13:46:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4aa3f63f{/api,null,AVAILABLE,@Spark}
2019-04-02 13:46:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ce16edc{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-04-02 13:46:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7b27d5e4{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-04-02 13:46:02 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://sharc-node176.shef.ac.uk:4042
2019-04-02 13:46:02 INFO  SparkContext:54 - Added file file:/home/acp18ca/asig2/Code/q1.py at file:/home/acp18ca/asig2/Code/q1.py with timestamp 1554209162338
2019-04-02 13:46:02 INFO  Utils:54 - Copying /home/acp18ca/asig2/Code/q1.py to /scratch/4030607.1.rse-com6012.q/spark-86a56440-589d-446b-af32-3436ab5effdb/userFiles-949cae85-37eb-4be5-9b09-dda868a7131e/q1.py
2019-04-02 13:46:02 INFO  Executor:54 - Starting executor ID driver on host localhost
2019-04-02 13:46:02 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37675.
2019-04-02 13:46:02 INFO  NettyBlockTransferService:54 - Server created on sharc-node176.shef.ac.uk:37675
2019-04-02 13:46:02 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-04-02 13:46:02 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, sharc-node176.shef.ac.uk, 37675, None)
2019-04-02 13:46:02 INFO  BlockManagerMasterEndpoint:54 - Registering block manager sharc-node176.shef.ac.uk:37675 with 16.9 GB RAM, BlockManagerId(driver, sharc-node176.shef.ac.uk, 37675, None)
2019-04-02 13:46:02 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, sharc-node176.shef.ac.uk, 37675, None)
2019-04-02 13:46:02 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, sharc-node176.shef.ac.uk, 37675, None)
2019-04-02 13:46:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6233aeac{/metrics/json,null,AVAILABLE,@Spark}
2019-04-02 13:46:02 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/acp18ca/asig2/spark-warehouse/').
2019-04-02 13:46:02 INFO  SharedState:54 - Warehouse path is 'file:/home/acp18ca/asig2/spark-warehouse/'.
2019-04-02 13:46:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c5de331{/SQL,null,AVAILABLE,@Spark}
2019-04-02 13:46:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6eb647ea{/SQL/json,null,AVAILABLE,@Spark}
2019-04-02 13:46:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@13098fc5{/SQL/execution,null,AVAILABLE,@Spark}
2019-04-02 13:46:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40a4a1d5{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-04-02 13:46:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45b7f212{/static/sql,null,AVAILABLE,@Spark}
2019-04-02 13:46:03 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2019-04-02 13:46:04 WARN  Utils:66 - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
10
Conda uses environments to load different sets of Python packages
type conda env list to see the environments availible.
2019-04-02 13:47:47 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-04-02 13:47:49 INFO  SparkContext:54 - Running Spark version 2.3.2
2019-04-02 13:47:49 WARN  SparkConf:66 - In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).
2019-04-02 13:47:49 INFO  SparkContext:54 - Submitted application: COM6012 Assignment 2
2019-04-02 13:47:49 INFO  SecurityManager:54 - Changing view acls to: acp18ca
2019-04-02 13:47:49 INFO  SecurityManager:54 - Changing modify acls to: acp18ca
2019-04-02 13:47:49 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-04-02 13:47:49 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-04-02 13:47:49 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(acp18ca); groups with view permissions: Set(); users  with modify permissions: Set(acp18ca); groups with modify permissions: Set()
2019-04-02 13:47:49 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 46219.
2019-04-02 13:47:49 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-04-02 13:47:49 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-04-02 13:47:49 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-04-02 13:47:49 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-04-02 13:47:49 INFO  DiskBlockManager:54 - Created local directory at /scratch/4030616.1.rse-com6012.q/blockmgr-7649a7d8-8717-410e-9fc6-436412002e8b
2019-04-02 13:47:49 INFO  MemoryStore:54 - MemoryStore started with capacity 16.9 GB
2019-04-02 13:47:49 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-04-02 13:47:49 INFO  log:192 - Logging initialized @3264ms
2019-04-02 13:47:49 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-04-02 13:47:49 INFO  Server:419 - Started @3317ms
2019-04-02 13:47:49 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2019-04-02 13:47:49 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2019-04-02 13:47:49 INFO  AbstractConnector:278 - Started ServerConnector@71ed2af7{HTTP/1.1,[http/1.1]}{0.0.0.0:4042}
2019-04-02 13:47:49 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4042.
2019-04-02 13:47:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32c81163{/jobs,null,AVAILABLE,@Spark}
2019-04-02 13:47:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5df376fe{/jobs/json,null,AVAILABLE,@Spark}
2019-04-02 13:47:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@8b76501{/jobs/job,null,AVAILABLE,@Spark}
2019-04-02 13:47:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a433ded{/jobs/job/json,null,AVAILABLE,@Spark}
2019-04-02 13:47:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c41eedd{/stages,null,AVAILABLE,@Spark}
2019-04-02 13:47:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7fed0539{/stages/json,null,AVAILABLE,@Spark}
2019-04-02 13:47:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@467e0881{/stages/stage,null,AVAILABLE,@Spark}
2019-04-02 13:47:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1e6d9a7{/stages/stage/json,null,AVAILABLE,@Spark}
2019-04-02 13:47:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@376af31a{/stages/pool,null,AVAILABLE,@Spark}
2019-04-02 13:47:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6d3e3248{/stages/pool/json,null,AVAILABLE,@Spark}
2019-04-02 13:47:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55a7f490{/storage,null,AVAILABLE,@Spark}
2019-04-02 13:47:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@623b3462{/storage/json,null,AVAILABLE,@Spark}
2019-04-02 13:47:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2a9f91c{/storage/rdd,null,AVAILABLE,@Spark}
2019-04-02 13:47:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1e193773{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-04-02 13:47:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74705354{/environment,null,AVAILABLE,@Spark}
2019-04-02 13:47:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd3f19c{/environment/json,null,AVAILABLE,@Spark}
2019-04-02 13:47:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@27f9063{/executors,null,AVAILABLE,@Spark}
2019-04-02 13:47:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@558a9df0{/executors/json,null,AVAILABLE,@Spark}
2019-04-02 13:47:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@23168ee6{/executors/threadDump,null,AVAILABLE,@Spark}
2019-04-02 13:47:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7319c409{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-04-02 13:47:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d1bbe81{/static,null,AVAILABLE,@Spark}
2019-04-02 13:47:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@18b9e397{/,null,AVAILABLE,@Spark}
2019-04-02 13:47:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4aa3f63f{/api,null,AVAILABLE,@Spark}
2019-04-02 13:47:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ce16edc{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-04-02 13:47:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7b27d5e4{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-04-02 13:47:49 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://sharc-node176.shef.ac.uk:4042
2019-04-02 13:47:50 INFO  SparkContext:54 - Added file file:/home/acp18ca/asig2/Code/q1.py at file:/home/acp18ca/asig2/Code/q1.py with timestamp 1554209270111
2019-04-02 13:47:50 INFO  Utils:54 - Copying /home/acp18ca/asig2/Code/q1.py to /scratch/4030616.1.rse-com6012.q/spark-96af09f1-5b24-48c1-b976-30fa768b7e0c/userFiles-05123b34-57b1-49e8-b7f7-ebc4dd1bf520/q1.py
2019-04-02 13:47:50 INFO  Executor:54 - Starting executor ID driver on host localhost
2019-04-02 13:47:50 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42284.
2019-04-02 13:47:50 INFO  NettyBlockTransferService:54 - Server created on sharc-node176.shef.ac.uk:42284
2019-04-02 13:47:50 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-04-02 13:47:50 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, sharc-node176.shef.ac.uk, 42284, None)
2019-04-02 13:47:50 INFO  BlockManagerMasterEndpoint:54 - Registering block manager sharc-node176.shef.ac.uk:42284 with 16.9 GB RAM, BlockManagerId(driver, sharc-node176.shef.ac.uk, 42284, None)
2019-04-02 13:47:50 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, sharc-node176.shef.ac.uk, 42284, None)
2019-04-02 13:47:50 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, sharc-node176.shef.ac.uk, 42284, None)
2019-04-02 13:47:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6233aeac{/metrics/json,null,AVAILABLE,@Spark}
2019-04-02 13:47:50 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/acp18ca/asig2/spark-warehouse/').
2019-04-02 13:47:50 INFO  SharedState:54 - Warehouse path is 'file:/home/acp18ca/asig2/spark-warehouse/'.
2019-04-02 13:47:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c5de331{/SQL,null,AVAILABLE,@Spark}
2019-04-02 13:47:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6eb647ea{/SQL/json,null,AVAILABLE,@Spark}
2019-04-02 13:47:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@13098fc5{/SQL/execution,null,AVAILABLE,@Spark}
2019-04-02 13:47:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40a4a1d5{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-04-02 13:47:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45b7f212{/static/sql,null,AVAILABLE,@Spark}
2019-04-02 13:47:50 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2019-04-02 13:47:52 WARN  Utils:66 - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
10
2019-04-02 13:51:56 WARN  BLAS:61 - Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2019-04-02 13:51:56 WARN  BLAS:61 - Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
[0.6634835963477698, 0.6630585057806182, 0.7022066421691878, 0.7030912710961497, 0.7038014008908815, 0.7039797836708499, 0.6666216635303535, 0.6618890574663236, 0.6637666126634211, 0.6992064557425596, 0.7022444209841767, 0.7031305150269876, 0.6954189016494151, 0.7036660806007199, 0.7041213591552544, 0.6352824383854049, 0.6020408033409334, 0.635575097929879, 0.6326803666839074, 0.6271484278740264, 0.6080885866950083, 0.6273395570830379, 0.6240534825661067]
trained models 23


Decision tree classifier models accuracy [0.6634835963477698, 0.6630585057806182, 0.7022066421691878, 0.7030912710961497, 0.7038014008908815, 0.7039797836708499]


Decision tree regression models accuracy [0.6666216635303535, 0.6618890574663236, 0.6637666126634211, 0.6992064557425596, 0.7022444209841767, 0.7031305150269876, 0.6954189016494151, 0.7036660806007199, 0.7041213591552544]


Logistic regression models accuracy [0.6352824383854049, 0.6020408033409334, 0.635575097929879, 0.6326803666839074, 0.6271484278740264, 0.6080885866950083, 0.6273395570830379, 0.6240534825661067]


Best decision tree classifier model
accuracy 0.7039797836708499
{Param(parent='Pipeline_4acea0a08bce514ec30f', name='stages', doc='a list of pipeline stages'): [VectorAssembler_4b1a90ec95ec1d769b7b, DecisionTreeClassifier_4f23a099aa3e8e242a90], Param(parent='DecisionTreeClassifier_4f23a099aa3e8e242a90', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15, Param(parent='DecisionTreeClassifier_4f23a099aa3e8e242a90', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32}


Best decision tree regression model
accuracy 0.7041213591552544
{Param(parent='Pipeline_4acea0a08bce514ec30f', name='stages', doc='a list of pipeline stages'): [VectorAssembler_4b1a90ec95ec1d769b7b, DecisionTreeRegressor_4bd2ad5a181299608ab7, Binarizer_484a88720d30bc3e0304], Param(parent='DecisionTreeRegressor_4bd2ad5a181299608ab7', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15, Param(parent='DecisionTreeRegressor_4bd2ad5a181299608ab7', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32}


Best logistic regression model
accuracy 0.635575097929879
{Param(parent='Pipeline_4acea0a08bce514ec30f', name='stages', doc='a list of pipeline stages'): [VectorAssembler_4b1a90ec95ec1d769b7b, LogisticRegression_4d5da05c625507f20b2f], Param(parent='LogisticRegression_4d5da05c625507f20b2f', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='LogisticRegression_4d5da05c625507f20b2f', name='maxIter', doc='max number of iterations (>= 0).'): 100, Param(parent='LogisticRegression_4d5da05c625507f20b2f', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0}


Final DTC Accuracy = 0.718262 
AUC: 0.7172138104895681
1st feature high_5 0.3261568954479019
2nd feature high_7 0.14401194448945717
3rd feature high_6 0.0986474517674539


Final DTR Accuracy = 0.717714 
AUC: 0.7166659527685514
1st feature high_5 0.3261568954479019
2nd feature high_7 0.14401194448945717
3rd feature high_6 0.0986474517674539


Final LR Accuracy = 0.635107 
AUC: 0.6356347292096343
1st feature high_6 0.8491208299816647
2nd feature low_6 0.6940737160890027
3rd feature high_2 0.6620167656510481
tiempo 596.2502872943878

real	10m2.503s
user	64m38.040s
sys	1m0.497s
